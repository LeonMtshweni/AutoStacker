; fiducial pointing: 1024+6806_12072015.ms/

[pipeline]
data_path = /simuCLASS/ ; where simulated data will be saved
project_name = emerlin-100fluxsource-matched-4day ; name prepended to all output
doskymodel = True ; simulate a new sky model
dosimdata = True ; simulate new visibility data
doimagedata = True ; create a new image

[observation]
telescope = e-merlin ; select which telescope, from {e-merlin, jvla, both}
uvcoverage = read ; simulate uv coverage or read it from pre-existing ms {simulate, read}
uvcoverage_ms_file = /simuCLASS/emerlin-firstlight-matched-1024+6806_4day.ms ; ms to read from if uvcoverage = read
lowest_frequency = 1.254463e9 ; lowest observing frequency in Hz
total_bandwidth = 512e6 ; total observing bandwidth in Hz
channel_width = 125e3 ; width of frequency channels in Hz
channel_separation = 125e3 ; distance between frequency channel centres in Hz
n_channels = 512 ; number of frequency channels per IF (or SPW if you prefer)
n_IFs = 8 ; number of IFs (or SPWs if you prefer)
t_int = 2 ; integration time per visibility in seconds
observation_time = 59529 ; total integration time in seconds
noisemode = uniform ; read a real set of noise rms per baseline and IF, or just use one uniform rms for all {real, uniform}
noise_file = /superclass/rms_1022+6812_30122014.p ; if noisemode=real, where to read the noise file from
uniform_noise = 0.4 ; if noisemode=uniform, the rms to use in Jy

[aips]
AIPSNumber = 4647 ; AIPS user number if imaging with AIPS
InDisk = 1 ; AIPS indisk if imaging with AIPS
clear_aips = True ; whether or not to tidy up after imaging with AIPS

[field]
name = testfield ; field name used for observation
fitsname = t-recs-1024-6806-emerlin-100fluxsource-matched-4day.fits ; fits image name of field
field_ra = 10:24:24.8 ; field ra in h:m:s
field_dec = +68:06:36.0 ; field dec in d:m:s
catalogue = /simuCLASS/catalogue_complete_edit.txt ; input catalogue name
agncatalogue = /simuCLASS/catalogues/catalogue_AGNs_complete_v2.fits.txt ; input catalogue name for agn

[skymodel]
catalogue_origin = trecs ; where catalogue originated from {trecs, pybdsm}
sizes_pdf_file = sizes_dist.txt ; file containing a pdf for starforming galaxy sizes [depracated]
pixel_scale = 0.045 ; size of sky model pixels in arcsec / pixel
field_of_view = 1 ; galaxies will be drawn on a grid 0.8 times this in arcminutes
ngals = -1 ; total number of galaxies to draw, or -1 for total number in catalogue
grid = False ; draw galaxies on a regular grid
doagn = False ; include agn or not
pickleagn = False ; create a pickle of individual agn image cutouts for testing
highfluxcut = False ; cut objects in the catalogue brighter than this flux
highfluxcut_value = 1000.e-6 ; in Jy
lowfluxcut = True ; cut objects in the catalogue fainter than this flux
lowfluxcut_value = 223.5e-6 ; in Jy
highsizecut = False ; cut objects in the catalogue larger than this size
highsizecut_value = 10.e0 ; in arcsec
lowsizecut = False ; cut objects in the catalogue smaller than this size
lowsizecut_value = 0.75e0 ; in arcsec
sizefactor = 1.e0 ; multiply all sizes in the catalogue by this factor
im3cat = False ; create a im3shape input catalogue for the cut catalogue
galaxy_profile = matched-exponential ; galaxy intensity profile to use {exponential, gaussian}
fluxscale = range ; constant gives all galaxies at the same flux, range gives their catalogue fluxes {constant, range}
fluxscale_constant_value = 500.e-6 ; if fluxscale=constant, flux of all galaxies in Jy

[primarybeam]
dopb = False ; include the primary beam model [currently emerlin only]
pb_model = 'jackson' ; which primary beam model to use {jackson, wrigley, wrigley-full}
nstokes = 1 ; number of stokes parameters to use in primary beam model [should leave at 1!]
nfreq = 8 ; number of different frequencies to calculate primary beam model at

[imager]
; NOTE: will create image at same pixel scale, fov as in skymodel
type = wsclean ; which imaging program to use {wsclean, casaclean, nwimager}
algo = hog ; which version of the CLEAN algorithm to use {hog, cs} which is {hogbom, cotton-schwab}
dopostagestamps = False ; make postage stamps of each CLEANed source, currently only implemented for wsclean
number_of_iterations = 5000 ; number of CLEAN iterations
n_cores = 8 ; if type=wsclean, number of cores to use
threshold = 0.000000025 ; threshold to clean down to in Jy
weight = natural ; weighting scheme to use in CLEAN algorithm {natural, uniform}
